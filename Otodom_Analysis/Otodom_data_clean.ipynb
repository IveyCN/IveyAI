{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9131a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.point import Point\n",
    "from snowflake.sqlalchemy import URL\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.connector.pandas_tools import pd_writer\n",
    "import time \n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc6eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f078c5a8",
   "metadata": {},
   "source": [
    "### Connection between python and snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad68796",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(URL(\n",
    "                    account = 'ZZMZZDH-AR84667',\n",
    "                    user = 'yifanj4',\n",
    "                    password = 'Z970710z',\n",
    "                    database = 'demo',\n",
    "                    schema = 'public',\n",
    "                    warehouse = 'demo_wh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d1c44",
   "metadata": {},
   "source": [
    "### Geodata transformation\n",
    "* Read data from snowflake\n",
    "* Apply geolocator function transfer data from (LATITUDE,LONGITUDE) format to actual address\n",
    "* update data as table to snowflake\n",
    "PS: since geolocator has limit usage, do not repeat the process too many time to meet the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b03d663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1188.5472559928894 seconds ---\n",
      "   RN                             LOCATION\n",
      "0   1                    52.23614,21.00817\n",
      "1   2                  52.336575,21.029306\n",
      "2   3  51.10710682881388,16.94346882507325\n",
      "3   4                    50.10361,20.00665\n",
      "4   5                  52.336575,21.029306\n",
      "--- 1189.8629581928253 seconds ---\n",
      "--- Error ---  Non-successful status code 429\n"
     ]
    }
   ],
   "source": [
    "geolocator = Nominatim(user_agent=\"otodomprojectanalysis\")\n",
    "with engine.connect() as conn:\n",
    "    try:\n",
    "        query = \"\"\" SELECT RN, concat(latitude,',',longitude) as LOCATION\n",
    "                    FROM (SELECT RN\n",
    "                            , SUBSTR(location, REGEXP_INSTR(location,' ',1,4)+1) AS LATITUDE \n",
    "                            , SUBSTR(location, REGEXP_INSTR(location,' ',1,1)+1, (REGEXP_INSTR(location,' ',1,2) - REGEXP_INSTR(location,' ',1,1) - 1) ) AS LONGITUDE\n",
    "                        FROM otodom_data_flatten\n",
    "                        ORDER BY rn  ) \"\"\"\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        df = pd.read_sql(query,conn)\n",
    "                      \n",
    "        df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "        \n",
    "        ddf = dd.from_pandas(df,npartitions=10)\n",
    "        print(ddf.head(5,npartitions=-1))\n",
    "\n",
    "        ddf['ADDRESS'] = ddf['LOCATION'].apply(lambda x: geolocator.reverse(x).raw['address'],meta=(None, 'str'))\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        pandas_df = ddf.compute()\n",
    "        print(pandas_df.head())\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        pandas_df.to_sql('otodom_data_flatten_address', con=engine, if_exists='append', index=False, chunksize=16000, method=pd_writer)\n",
    "    except Exception as e:\n",
    "        print('--- Error --- ',e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efdac9",
   "metadata": {},
   "source": [
    "### Text Translate\n",
    "* Import gspread library, then apply google sheet API to connect python with googlesheet\n",
    "* Apply google translate to translate text data \n",
    "* load data back to snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21eaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f11618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spreadsheet OTODOM_ANALYSIS_1 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_2 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_3 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_4 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_5 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_6 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_7 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_8 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_9 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_10 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_11 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_12 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_13 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_14 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_15 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_16 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_17 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_18 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_19 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_20 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_21 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_22 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_23 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_24 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_25 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_26 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_27 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_28 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_29 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_30 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_31 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_32 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_33 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_34 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_35 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_36 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_37 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_38 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_39 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_40 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_41 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_42 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_43 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_44 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_45 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_46 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_47 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_48 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_49 created!\n",
      "Spreadsheet OTODOM_ANALYSIS_50 created!\n",
      "--- Error ---  {'code': 403, 'message': 'Rate limit exceeded. User message: \"Sorry, you have exceeded your sharing quota.\"', 'errors': [{'message': 'Rate limit exceeded. User message: \"Sorry, you have exceeded your sharing quota.\"', 'domain': 'usageLimits', 'reason': 'sharingRateLimitExceeded'}]}\n",
      "--- 633.9118280410767 seconds ---\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    try:\n",
    "        query = \"\"\" SELECT RN, TITLE FROM otodom_data_flatten ORDER BY rn\"\"\"\n",
    "\n",
    "        df = pd.read_sql(query,conn)\n",
    "\n",
    "        gc = gspread.service_account()\n",
    "\n",
    "        loop_counter = 0\n",
    "        chunk_size = 1000\n",
    "        file_name = 'OTODOM_ANALYSIS_'\n",
    "        user_email = 'y********5@gmail.com'\n",
    "\n",
    "        for i in range(0,len(df),chunk_size):\n",
    "            loop_counter += 1\n",
    "            df_in = df.iloc[i:(i+chunk_size), :]\n",
    "\n",
    "            spreadsheet_title = file_name + str(loop_counter)\n",
    "            try:\n",
    "                locals()['sh'+str(loop_counter)] = gc.open(spreadsheet_title)\n",
    "            except gspread.SpreadsheetNotFound:\n",
    "                locals()['sh'+str(loop_counter)] = gc.create(spreadsheet_title)\n",
    "\n",
    "            locals()['sh'+str(loop_counter)].share(user_email, perm_type='user', role='writer')\n",
    "            wks = locals()['sh'+str(loop_counter)].get_worksheet(0)\n",
    "            wks.resize(len(df_in)+1)\n",
    "            set_with_dataframe(wks, df_in)   \n",
    "                \n",
    "            column = 'C'   # Column to apply the formula \n",
    "            start_row = 2  # Starting row to apply the formula\n",
    "            end_row = wks.row_count   # Ending row to apply the formula\n",
    "            cell_range = f'{column}{start_row}:{column}{end_row}' \n",
    "            curr_row = start_row\n",
    "            cell_list = wks.range(cell_range)\n",
    "            \n",
    "            for cell in cell_list:\n",
    "                cell.value = f'=GOOGLETRANSLATE(B{curr_row},\"pl\",\"en\")'\n",
    "                curr_row += 1\n",
    "                \n",
    "            # Update the worksheet with the modified cells\n",
    "            wks.update_cells(cell_list, value_input_option='USER_ENTERED')\n",
    "\n",
    "            print(f'Spreadsheet {spreadsheet_title} created!')\n",
    "\n",
    "            df_log = pd.DataFrame({'ID':[loop_counter], 'SPREADSHEET_NAME':[spreadsheet_title]})\n",
    "            df_log.to_sql('otodom_data_log', con=engine, if_exists='append', index=False, chunksize=16000, method=pd_writer)\n",
    "\n",
    "\n",
    "            # df_out = get_as_dataframe(wks, usecols=[0,1,2,3], nrows=end_row, header=None, skiprows=1)\n",
    "            # print(f'Spreadsheet {locals()[\"sh\"+str(loop_counter)]} loaded back to DataFrame!')\n",
    "            \n",
    "            # df_out.columns = ['RN', 'TITLE', 'LOCATION', 'TITLE_ENG']\n",
    "\n",
    "            # df_out.to_sql('otodom_data_transformed', con=engine, if_exists='append', index=False, chunksize=16000, method=pd_writer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('--- Error --- ',e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "engine.dispose()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da70ec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spreadsheet OTODOM_ANALYSIS_1 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_2 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_3 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_1 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_2 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_3 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_1 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_1 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_2 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_3 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_4 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_5 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_6 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_7 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_8 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_9 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_10 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_11 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_12 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_13 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_14 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_15 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_16 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_1 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_2 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_3 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_4 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_5 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_6 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_7 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_8 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_9 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_10 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_11 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_12 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_13 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_14 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_15 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_16 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_17 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_18 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_19 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_20 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_21 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_22 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_23 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_24 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_25 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_26 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_27 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_1 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_2 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_3 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_4 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_5 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_6 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_7 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_8 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_9 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_10 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_11 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_12 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_13 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_14 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_15 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_16 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_17 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_18 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_19 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_20 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_21 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_22 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_23 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_24 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_25 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_26 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_27 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_28 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_29 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_30 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_31 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_32 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_33 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_34 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_35 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_36 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_37 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_38 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_39 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_40 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_41 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_42 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_43 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_44 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_45 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_46 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_47 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_48 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_49 loaded back to DataFrame!\n",
      "Spreadsheet OTODOM_ANALYSIS_50 loaded back to DataFrame!\n",
      "--- 1187.871570110321 seconds ---\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    try:\n",
    "        query = \"\"\" SELECT ID, SPREADSHEET_NAME FROM otodom_data_log \"\"\"\n",
    "        df = pd.read_sql(query,conn)\n",
    "        df.columns = map(lambda x: str(x).upper(), df.columns)\n",
    "\n",
    "        gc = gspread.service_account()\n",
    "        loop_counter = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            loop_counter += 1\n",
    "            locals()['sh'+str(loop_counter)] = gc.open(row['SPREADSHEET_NAME'])\n",
    "            wks = locals()['sh'+str(loop_counter)].get_worksheet(0)\n",
    "            df_out = get_as_dataframe(wks, usecols=[0,1,2], nrows=wks.row_count, header=None, skiprows=1, evaluate_formulas=True)\n",
    "            print('Spreadsheet '+row['SPREADSHEET_NAME']+' loaded back to DataFrame!')\n",
    "            \n",
    "            df_out.columns = ['RN', 'TITLE', 'TITLE_ENG']\n",
    "            df_out.to_sql('otodom_data_flatten_translate', con=engine, if_exists='append', index=False, chunksize=16000, method=pd_writer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('--- Error --- ',e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "engine.dispose()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
